#!/usr/bin/env python3
"""
Enochian Cyphers Batch Governor Quest Generator

Implements batch AI processing for 91 Governor Angels to autonomously design
their own questlines using OpenAI/Anthropic APIs.

This addresses the expert feedback gap: transforming static quest generation
into dynamic AI-driven content where each governor creates authentic,
personalized questlines based on their unique wisdom and personality.
"""

import json
import os
import asyncio
import logging
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import hashlib
import re

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class QuestlineQuest:
    """Individual quest within a questline"""
    quest_id: str
    title: str
    description: str
    objectives: List[str]
    wisdom_taught: str
    enochian_invocation: str
    tradition_references: List[str]
    difficulty_level: int
    completion_criteria: List[str]
    rewards_suggestion: str
    branching_paths: Optional[Dict[str, str]] = None

@dataclass
class GovernorQuestline:
    """Complete questline generated by a governor"""
    governor_name: str
    questline_title: str
    narrative_arc: str
    total_quests: int
    quests: List[QuestlineQuest]
    wisdom_focus: str
    generation_metadata: Dict[str, Any]

@dataclass
class BatchProcessingConfig:
    """Configuration for batch processing"""
    api_provider: str = "openai"  # "openai" or "anthropic"
    model_name: str = "gpt-4"
    batch_size: int = 15
    delay_between_batches: float = 30.0
    max_retries: int = 3
    timeout_seconds: int = 120
    cost_limit_usd: float = 100.0
    output_directory: str = "generated_questlines"

class AIProviderInterface:
    """Abstract interface for AI providers"""
    
    def __init__(self, config: BatchProcessingConfig):
        self.config = config
        self.total_cost = 0.0
        self.api_calls_made = 0
    
    async def generate_questline(self, governor_prompt: str, governor_name: str) -> Optional[Dict[str, Any]]:
        """Generate questline for a governor - to be implemented by providers"""
        raise NotImplementedError
    
    def estimate_cost(self, prompt_tokens: int, completion_tokens: int = 2000) -> float:
        """Estimate cost for API call"""
        raise NotImplementedError

class OpenAIProvider(AIProviderInterface):
    """OpenAI API provider implementation"""
    
    def __init__(self, config: BatchProcessingConfig):
        super().__init__(config)
        self.api_key = os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY environment variable not set")
        
        # Pricing per 1K tokens (as of 2024)
        self.pricing = {
            'gpt-4': {'input': 0.03, 'output': 0.06},
            'gpt-4-turbo': {'input': 0.01, 'output': 0.03},
            'gpt-3.5-turbo': {'input': 0.001, 'output': 0.002}
        }
    
    async def generate_questline(self, governor_prompt: str, governor_name: str) -> Optional[Dict[str, Any]]:
        """Generate questline using OpenAI API"""
        try:
            # Import here to avoid dependency issues if not installed
            import openai
            
            client = openai.AsyncOpenAI(api_key=self.api_key)
            
            # Create the full prompt for questline generation
            full_prompt = f"""{governor_prompt}

QUESTLINE GENERATION TASK:
Generate a complete 15-quest storyline as {governor_name}. Return your response as a JSON object with this exact structure:

{{
    "questline_title": "Your questline title",
    "narrative_arc": "Brief description of the overall story arc",
    "wisdom_focus": "The specific wisdom you're teaching",
    "quests": [
        {{
            "quest_id": "QUEST_001",
            "title": "Quest title",
            "description": "Detailed quest description",
            "objectives": ["Objective 1", "Objective 2"],
            "wisdom_taught": "Specific wisdom or lesson",
            "enochian_invocation": "Enochian invocation or prayer",
            "tradition_references": ["tradition1", "tradition2"],
            "difficulty_level": 5,
            "completion_criteria": ["Criteria 1", "Criteria 2"],
            "rewards_suggestion": "Suggested rewards",
            "branching_paths": {{"success": "Next quest on success", "failure": "Alternative path"}}
        }}
    ]
}}

Generate exactly 15 quests following the narrative arc structure. Ensure each quest builds upon the previous ones and maintains authentic Enochian magical foundations."""

            response = await client.chat.completions.create(
                model=self.config.model_name,
                messages=[
                    {"role": "system", "content": "You are an expert in Enochian magic and mystical traditions. Generate authentic, educational questlines that teach genuine spiritual wisdom."},
                    {"role": "user", "content": full_prompt}
                ],
                max_tokens=4000,
                temperature=0.7,
                timeout=self.config.timeout_seconds
            )
            
            # Extract and parse response
            content = response.choices[0].message.content
            
            # Calculate cost
            prompt_tokens = response.usage.prompt_tokens
            completion_tokens = response.usage.completion_tokens
            cost = self.estimate_cost(prompt_tokens, completion_tokens)
            self.total_cost += cost
            self.api_calls_made += 1
            
            logger.info(f"Generated questline for {governor_name}: {prompt_tokens} + {completion_tokens} tokens, ${cost:.4f}")
            
            # Parse JSON response
            try:
                questline_data = json.loads(content)
                questline_data['generation_metadata'] = {
                    'provider': 'openai',
                    'model': self.config.model_name,
                    'prompt_tokens': prompt_tokens,
                    'completion_tokens': completion_tokens,
                    'cost_usd': cost,
                    'timestamp': datetime.now().isoformat()
                }
                return questline_data
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON response for {governor_name}: {e}")
                # Try to extract JSON from response
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    try:
                        questline_data = json.loads(json_match.group())
                        questline_data['generation_metadata'] = {
                            'provider': 'openai',
                            'model': self.config.model_name,
                            'prompt_tokens': prompt_tokens,
                            'completion_tokens': completion_tokens,
                            'cost_usd': cost,
                            'timestamp': datetime.now().isoformat(),
                            'parsing_note': 'Extracted from partial response'
                        }
                        return questline_data
                    except:
                        pass
                return None
                
        except Exception as e:
            logger.error(f"Error generating questline for {governor_name}: {e}")
            return None
    
    def estimate_cost(self, prompt_tokens: int, completion_tokens: int = 2000) -> float:
        """Estimate cost for OpenAI API call"""
        model_pricing = self.pricing.get(self.config.model_name, self.pricing['gpt-4'])
        input_cost = (prompt_tokens / 1000) * model_pricing['input']
        output_cost = (completion_tokens / 1000) * model_pricing['output']
        return input_cost + output_cost

class AnthropicProvider(AIProviderInterface):
    """Anthropic API provider implementation"""
    
    def __init__(self, config: BatchProcessingConfig):
        super().__init__(config)
        self.api_key = os.getenv('ANTHROPIC_API_KEY')
        if not self.api_key:
            logger.warning("ANTHROPIC_API_KEY not set, Anthropic provider unavailable")
        
        # Pricing per 1K tokens (as of 2024)
        self.pricing = {
            'claude-3-opus': {'input': 0.015, 'output': 0.075},
            'claude-3-sonnet': {'input': 0.003, 'output': 0.015},
            'claude-3-haiku': {'input': 0.00025, 'output': 0.00125}
        }
    
    async def generate_questline(self, governor_prompt: str, governor_name: str) -> Optional[Dict[str, Any]]:
        """Generate questline using Anthropic API"""
        if not self.api_key:
            logger.error("Anthropic API key not available")
            return None
        
        try:
            # Import here to avoid dependency issues
            import anthropic
            
            client = anthropic.AsyncAnthropic(api_key=self.api_key)
            
            # Similar implementation to OpenAI but with Anthropic's format
            # Implementation would go here...
            logger.warning("Anthropic provider not fully implemented yet")
            return None
            
        except Exception as e:
            logger.error(f"Error with Anthropic API for {governor_name}: {e}")
            return None
    
    def estimate_cost(self, prompt_tokens: int, completion_tokens: int = 2000) -> float:
        """Estimate cost for Anthropic API call"""
        model_pricing = self.pricing.get(self.config.model_name, self.pricing['claude-3-sonnet'])
        input_cost = (prompt_tokens / 1000) * model_pricing['input']
        output_cost = (completion_tokens / 1000) * model_pricing['output']
        return input_cost + output_cost

class BatchGovernorQuestGenerator:
    """Main batch processing system for governor questlines"""
    
    def __init__(self, config: BatchProcessingConfig):
        self.config = config
        self.provider = self._create_provider()
        self.generated_questlines = {}
        self.failed_generations = []
        
        # Create output directory
        Path(self.config.output_directory).mkdir(exist_ok=True)
    
    def _create_provider(self) -> AIProviderInterface:
        """Create AI provider based on configuration"""
        if self.config.api_provider == "openai":
            return OpenAIProvider(self.config)
        elif self.config.api_provider == "anthropic":
            return AnthropicProvider(self.config)
        else:
            raise ValueError(f"Unsupported API provider: {self.config.api_provider}")
    
    def load_agent_prompts(self, prompts_file: str = "governor_agent_prompts.json") -> Dict[str, Any]:
        """Load governor agent prompts"""
        try:
            with open(prompts_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"Agent prompts file not found: {prompts_file}")
            logger.info("Run governor_agent_prompt_generator.py first to generate prompts")
            raise
    
    def validate_questline(self, questline_data: Dict[str, Any], governor_name: str, validation_keywords: List[str]) -> bool:
        """Validate generated questline for authenticity and completeness"""
        try:
            # Check required fields
            required_fields = ['questline_title', 'narrative_arc', 'quests']
            for field in required_fields:
                if field not in questline_data:
                    logger.warning(f"Missing required field '{field}' for {governor_name}")
                    return False
            
            # Check quest count
            quests = questline_data.get('quests', [])
            if len(quests) < 10 or len(quests) > 20:
                logger.warning(f"Invalid quest count ({len(quests)}) for {governor_name}")
                return False
            
            # Check for Enochian adherence
            full_text = json.dumps(questline_data).lower()
            enochian_keywords = ['aethyr', 'enochian', 'angelic', 'governor', 'invocation']
            found_keywords = sum(1 for keyword in enochian_keywords if keyword in full_text)
            
            if found_keywords < 3:
                logger.warning(f"Insufficient Enochian content for {governor_name}")
                return False
            
            # Check validation keywords
            validation_found = sum(1 for keyword in validation_keywords if keyword.lower() in full_text)
            if validation_found < len(validation_keywords) * 0.3:  # At least 30% of keywords
                logger.warning(f"Insufficient validation keywords for {governor_name}")
                return False
            
            logger.info(f"Questline validation passed for {governor_name}")
            return True
            
        except Exception as e:
            logger.error(f"Error validating questline for {governor_name}: {e}")
            return False
    
    async def generate_single_questline(self, governor_name: str, agent_prompt_data: Dict[str, Any]) -> Optional[GovernorQuestline]:
        """Generate questline for a single governor"""
        logger.info(f"Generating questline for {governor_name}")
        
        # Check cost limit
        if self.provider.total_cost >= self.config.cost_limit_usd:
            logger.error(f"Cost limit reached: ${self.provider.total_cost:.2f}")
            return None
        
        # Build full prompt
        full_prompt = f"""{agent_prompt_data['personality_core_prompt']}

{agent_prompt_data['enochian_base_instructions']}

{agent_prompt_data['lighthouse_knowledge_context']}

{agent_prompt_data['questline_structure_directive']}"""
        
        # Generate with retries
        for attempt in range(self.config.max_retries):
            try:
                questline_data = await self.provider.generate_questline(full_prompt, governor_name)
                
                if questline_data and self.validate_questline(
                    questline_data, governor_name, agent_prompt_data['validation_keywords']
                ):
                    # Convert to structured format
                    quests = []
                    for i, quest_data in enumerate(questline_data.get('quests', [])):
                        quest = QuestlineQuest(
                            quest_id=quest_data.get('quest_id', f"{governor_name}_QUEST_{i+1:03d}"),
                            title=quest_data.get('title', f'Quest {i+1}'),
                            description=quest_data.get('description', ''),
                            objectives=quest_data.get('objectives', []),
                            wisdom_taught=quest_data.get('wisdom_taught', ''),
                            enochian_invocation=quest_data.get('enochian_invocation', ''),
                            tradition_references=quest_data.get('tradition_references', []),
                            difficulty_level=quest_data.get('difficulty_level', 5),
                            completion_criteria=quest_data.get('completion_criteria', []),
                            rewards_suggestion=quest_data.get('rewards_suggestion', ''),
                            branching_paths=quest_data.get('branching_paths')
                        )
                        quests.append(quest)
                    
                    questline = GovernorQuestline(
                        governor_name=governor_name,
                        questline_title=questline_data.get('questline_title', f'{governor_name} Wisdom Path'),
                        narrative_arc=questline_data.get('narrative_arc', ''),
                        total_quests=len(quests),
                        quests=quests,
                        wisdom_focus=questline_data.get('wisdom_focus', ''),
                        generation_metadata=questline_data.get('generation_metadata', {})
                    )
                    
                    logger.info(f"Successfully generated questline for {governor_name}: {len(quests)} quests")
                    return questline
                
            except Exception as e:
                logger.error(f"Attempt {attempt + 1} failed for {governor_name}: {e}")
                if attempt < self.config.max_retries - 1:
                    await asyncio.sleep(5)  # Wait before retry
        
        logger.error(f"Failed to generate questline for {governor_name} after {self.config.max_retries} attempts")
        self.failed_generations.append(governor_name)
        return None
    
    async def generate_batch(self, governor_batch: List[Tuple[str, Dict[str, Any]]]) -> List[GovernorQuestline]:
        """Generate questlines for a batch of governors"""
        logger.info(f"Processing batch of {len(governor_batch)} governors")
        
        tasks = []
        for governor_name, agent_prompt_data in governor_batch:
            task = self.generate_single_questline(governor_name, agent_prompt_data)
            tasks.append(task)
        
        # Execute batch concurrently
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filter successful results
        successful_questlines = []
        for result in results:
            if isinstance(result, GovernorQuestline):
                successful_questlines.append(result)
            elif isinstance(result, Exception):
                logger.error(f"Batch generation error: {result}")
        
        logger.info(f"Batch completed: {len(successful_questlines)} successful, {len(governor_batch) - len(successful_questlines)} failed")
        return successful_questlines
    
    async def generate_all_questlines(self) -> Dict[str, GovernorQuestline]:
        """Generate questlines for all 91 governors"""
        logger.info("Starting batch generation for all 91 governors")
        
        # Load agent prompts
        agent_prompts = self.load_agent_prompts()
        
        # Create batches
        governor_items = list(agent_prompts.items())
        batches = []
        for i in range(0, len(governor_items), self.config.batch_size):
            batch = governor_items[i:i + self.config.batch_size]
            batches.append(batch)
        
        logger.info(f"Created {len(batches)} batches of size {self.config.batch_size}")
        
        # Process batches
        all_questlines = {}
        for i, batch in enumerate(batches):
            logger.info(f"Processing batch {i + 1}/{len(batches)}")
            
            batch_questlines = await self.generate_batch(batch)
            
            # Store results
            for questline in batch_questlines:
                all_questlines[questline.governor_name] = questline
                self.generated_questlines[questline.governor_name] = questline
            
            # Save intermediate results
            self.save_questlines(f"batch_{i+1}_questlines.json", batch_questlines)
            
            # Delay between batches (except last)
            if i < len(batches) - 1:
                logger.info(f"Waiting {self.config.delay_between_batches} seconds before next batch...")
                await asyncio.sleep(self.config.delay_between_batches)
        
        logger.info(f"Batch generation complete: {len(all_questlines)} questlines generated")
        logger.info(f"Total cost: ${self.provider.total_cost:.2f}")
        logger.info(f"Failed generations: {len(self.failed_generations)}")
        
        return all_questlines
    
    def save_questlines(self, filename: str, questlines: List[GovernorQuestline]):
        """Save questlines to JSON file"""
        output_path = Path(self.config.output_directory) / filename
        
        export_data = {}
        for questline in questlines:
            export_data[questline.governor_name] = {
                'governor_name': questline.governor_name,
                'questline_title': questline.questline_title,
                'narrative_arc': questline.narrative_arc,
                'total_quests': questline.total_quests,
                'wisdom_focus': questline.wisdom_focus,
                'generation_metadata': questline.generation_metadata,
                'quests': [asdict(quest) for quest in questline.quests]
            }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Saved {len(questlines)} questlines to {output_path}")

async def main():
    """Main function for batch questline generation"""
    # Configuration
    config = BatchProcessingConfig(
        api_provider="openai",
        model_name="gpt-4",
        batch_size=10,  # Conservative batch size
        delay_between_batches=30.0,
        max_retries=3,
        cost_limit_usd=50.0,  # Safety limit
        output_directory="generated_questlines"
    )
    
    # Create generator
    generator = BatchGovernorQuestGenerator(config)
    
    # Generate all questlines
    questlines = await generator.generate_all_questlines()
    
    # Save final results
    generator.save_questlines("all_governor_questlines.json", list(questlines.values()))
    
    # Summary
    logger.info(f"\n=== BATCH GENERATION COMPLETE ===")
    logger.info(f"Total Questlines Generated: {len(questlines)}")
    logger.info(f"Total API Calls: {generator.provider.api_calls_made}")
    logger.info(f"Total Cost: ${generator.provider.total_cost:.2f}")
    logger.info(f"Failed Generations: {len(generator.failed_generations)}")
    if generator.failed_generations:
        logger.info(f"Failed Governors: {', '.join(generator.failed_generations)}")

if __name__ == "__main__":
    asyncio.run(main())
